ModellingBase::setMesh() copying new mesh ... Found datafile: 51 electrodes
Found: 51 free-electrodes
rMin = 0.5, rMax = 100
NGauLeg + NGauLag for inverse Fouriertransformation: 13 + 4
Found non-Neumann domain
0.0125568 s
FOP updating mesh dependencies ... 1.701e-06 s
Calculating response for model: min = 50 max = 200
Allocating memory for primary potential...... 0.00291104

No primary potential for secondary field calculation. Calculating analytically...
Forward: time: 0.171595s
Response: min = 98.6119 max = 219.048 mean = 173.871
Reciprocity rms(modelReciprocity) 0.408989%, max: 1.53118%
relativeError set to a value > 0.5 .. assuming this is a percentage Error level dividing them by 100
Iteration #0, objective value: 30.93863864722905
Iteration #1, objective value: 15.997077608594946
============================
Summary for inversion result
============================
SUCCESS
----------------------------
model: [5.29627142 5.3053673  5.32533978 5.34108737 5.28957644 5.31664945
 5.31690355 5.30481273 5.30600768 5.3323181  5.30877633 5.31441479
 5.29499591 5.30736811 5.29032367 5.33381713 5.31107416 5.30047186
 5.31881338 5.30009382 5.3257     5.22706747 5.31561874 5.29472746
 5.31919085 5.30093757 5.3025506  5.29258859 5.30297055 5.29769806
 5.30866772 5.30739703 5.30710493 5.3233785  5.27737304 5.30518254
 5.32104688 5.32650451 5.32876649 5.32472183 5.30150023 5.30068466
 5.29826877 5.29972086 5.2799071  5.3063462  5.32590148 5.30472539
 5.31459569 5.3171524  5.31589139 5.30362823 5.30509222 5.30070947
 5.30885481 5.30698394 5.28741747 5.05369063 5.31145009 5.28218622
 5.31653203 5.30612439 5.27776848 5.32915785 5.28597473 5.30803408
 5.28980506 5.29239584 5.29448409 5.28980272 5.28340286 5.30480175
 5.27414382 5.33922302 5.30601917 5.30029149 5.29860411 5.27788114
 5.34975378 5.28523103 5.33177957 5.30102242 5.30591428 5.33453525
 5.30785205 5.30028254 5.34303301 5.27888649 5.2968941  5.30418844
 5.32382668 5.31822124 5.30144942 5.31789577 5.30013129 5.29680923
 5.29565357 5.32977573 5.29026049 5.31533956 5.3063531  5.28057491
 5.30190702 5.2894496  5.31235418 5.29033001 5.2841154  5.3446806
 5.3055323  5.29472134 5.28887945 5.27322008 5.31450382 5.31395854
 5.28922278 5.29360021 5.30559741 5.27157697 5.30965621 5.29315119
 5.30546056 5.31518642 5.31123506 5.31654668 5.31165164 5.28057999
 5.28227944 5.3230818  5.31352304 5.29619551 5.34307927 5.31861345
 5.30442755 5.33471829 5.32069563 5.32438781 5.30159036 5.2878834
 5.29283751 5.29577373 5.30832752 5.29768903 5.31259513 5.31808607
 5.31317324 5.2785826  5.31846049 5.2874336  5.32008828 5.30976601
 5.29842774 5.30694281 5.3057993  5.30714253 5.29479895 5.31437108
 5.32153072 5.29529722 5.26931439 5.29987165 5.28960163 5.27641811
 5.29431998 5.29645848 5.30677849 5.27309399 5.31086607 5.31069352
 5.3012241  5.29855141 5.30690917 5.30241526 5.30123559 5.28848123
 5.30344195 5.28571254 5.2948188  5.29171985 5.31581877 5.30310897
 5.30282794 5.31499846 5.29422578 5.28824877 5.31163131 5.30388838
 5.29620302 5.28585831 5.31388881 5.30621491 5.31518452 5.3079236
 5.32211195 5.32381787 5.29451228 5.32661328 5.27755832 5.31691761
 5.30938784 5.30775682 5.30446434 5.29883322 5.30725316 5.30672208
 5.31752611 5.29870665 5.29879581 5.3001588  5.28801774 5.30422914
 5.28533884 5.31578678 5.35033001 5.30666913 5.29403439 5.30019035
 5.31098444 5.28428035 5.30018123 5.31093861 5.30967989 5.33927707
 5.29025887 5.31961899 5.29827491 5.32778746 5.32499987 5.32123624
 5.31913764 5.2961117  5.3292456  5.28483704 5.29216869 5.33316391
 5.3342069  5.32175076 5.2787213  5.31228462 5.29467668 5.30223208
 5.29808927 5.28352258 5.31314932 5.29892262 5.28938399 5.30081096
 5.28526568 5.29475596 5.30570323 5.30326191 5.2822242  5.32147001
 5.32890454 5.31508146 5.30516584 5.28572462 5.28897241 5.30647546
 5.27770824 5.30684487 5.30042107 5.31391598 5.30395507 5.29952968
 5.30608867 5.29297604 5.29991784 5.30495045 5.29893111 5.2989435
 5.28647157 5.30253879 5.28194284 5.29979107 5.31759989 5.30642031
 5.3001215  5.2904935  5.30461527 5.28836452 5.31465884 5.30761372
 5.29796049 5.29344915 5.30737736 5.29367386 5.30292977 5.29762043
 5.30838072 5.31948189 5.30381779 5.28909705 5.28712376 5.31253134
 5.29699576 5.31691003 5.30671809 5.28863566 5.31561429 5.29235883
 5.30467806 5.30788855 5.31829698 5.30975273 5.32777758 5.29741598
 5.33589113 5.35042491 5.3494895  5.29838184 5.31962392 5.25146465
 5.33798818 5.29808135 5.31261889 5.3403163  5.2952008  5.31129917
 5.31701589 5.32107814 5.27747377 5.31652519 5.3139914  5.02311536
 5.28976945 5.29453295 5.31522757 5.3099478  5.30426103 5.30463944
 5.31345588 5.31526867 5.30926634 5.30458814 5.30283545 4.08520423
 5.30157004 5.3019462  5.29888969 5.3074797  5.32592467 5.3160985
 5.32067854 5.30222318 5.28628546 5.29863571 5.30178797 5.30812995
 5.29579173 5.29540866 5.29671593 5.29351585 5.29418921 5.28558521
 5.28282798 5.31293501 5.29490706 5.27079121 5.29030254 5.3168041
 5.30375425 5.30175899 5.31020683 5.29724901 5.29951246 5.31502404
 5.29251416 5.30735084 5.38158649 5.28623665 5.27948099 5.2746843
 5.31278786 5.30349006 5.32204376 5.30534848 5.29012343 5.30277743
 5.32820803 5.36020872 5.35663649 5.28467323 5.32341878 5.2927124
 5.37036426 5.33375868 5.34293072 5.22934985 5.22245796 5.33956971
 5.20845831 5.28770751 3.53748445 5.36972943 5.31583605 5.31556066
 5.34200207 5.3516784  5.33413578 4.99552728 5.31514082 5.32891914
 5.25399539 5.30061153 4.88451623 5.3174726  5.33258031 5.12869854
 5.3120657  5.30738227 5.30499337 5.30551362 5.30298904 5.31699901
 5.30967429 5.29482313 5.28901055 5.30280851 5.28765221 5.28285877
 5.30691779 5.31129047 5.2986715  5.32090994 5.29335147 5.28948246
 5.29609468 5.29028377 5.31973679 5.28844234 5.28965391 5.30100601
 5.31028387 5.30732852 5.3027661  5.30600121 5.29007928 5.30206783
 5.29520371 5.27917302 5.32462372 5.30450007 5.31679517 5.31607669
 5.29518828 5.29192084 5.28324331 5.30750029 5.28980541 5.29484647
 5.30320988 5.31844089 5.34888373 5.30524637 5.30420649 5.30957792
 5.30092792 5.29643024 5.29931476 5.27850264 5.30996854 5.31155771
 5.33597035 5.3210806  5.30370079 5.34008555 5.28900703 5.31188552
 5.29193734 5.30200165 5.33840831 5.29272203 5.27504201 5.2831573
 5.30545727 5.30153496 5.28935655 5.29731647 5.30165446 5.29937801
 5.29372746 5.30798015 5.33051235 5.37183695 5.29059602 5.30296476
 5.32017286 5.33364529 5.332704   5.32766222 5.33090168 5.17059895
 5.30031585 5.28153767 5.30453843 5.32200141 5.31735111 5.30059102
 5.29136926 5.29102164 5.33205444 5.29155186 5.29485477 5.29689662
 5.31361033 5.29605811 5.31795186 5.32456364 5.27335135 5.31690685
 5.39978723 5.31177539 5.32539273 5.29653266 5.30732914 5.32630019
 5.29022851 5.20663134 5.34195037 5.32604125 5.35074332 5.31471138
 5.3206548  5.32293869 5.29897042 5.33136151 5.30802267 5.34034734
 5.36453462 5.40170379 5.30496779 5.32173098 5.34811582 5.34789395
 5.41787775 5.30787237 5.39907269 5.341744   5.34997152 5.39432642
 5.36156521 5.3474659  5.39325929 5.35396331 5.35968428 5.38334174
 4.83412017 5.36137239 5.29943933 5.30379297 5.30344783 5.28074092
 5.0613672  5.30966108 5.30301711 5.29786965 5.31735793 5.30057703
 5.31213786 5.32038393 5.35642243 5.36477743 5.32152819 5.34283936
 5.35441188 4.98178797 5.28726015 5.2898831  5.28610915 5.29096404
 5.28766173 5.29044156 5.27911909 5.28770053 5.28321944 5.30293515
 5.28718138 5.29109847 5.2879449  5.29992949 5.31582242 5.28044334
 4.82417957 4.83660776 5.32508572 5.33589731 5.32504245 5.32443471
 5.34024498 5.31961189 5.24415907 4.42973266 5.29604113 5.28125127
 5.29379564 5.27729955 5.30124915 5.29571446 5.32745212 5.2685653
 5.28375276 5.30774916 5.3803044  5.34220732 5.36375208 5.40135851
 4.4037819  4.99441109 5.28913548 5.26553353 5.29417875 5.28389847
 5.28438348 5.27633299 5.38801926 5.30543399 5.29143909 5.28598391
 4.55470895 4.9688838  4.48345937 5.34797905 4.42408124 4.42966162
 5.3155263  5.27244206 5.3161692  5.32026726 5.3176198  5.29335473
 5.30147266 5.29897702 5.31535282 5.24918244 5.29639647 5.28139597
 4.98617943 4.10271805 4.80921102 3.98225959 5.32972682 5.27620495
 5.31468111 5.27990513 5.30352743 5.28746462 3.51107618 5.20177619
 5.29868588 5.29651444 5.2821093  5.26762329 5.28043381 5.27364139
 5.27992315 5.27824067 5.31486232 5.30138085 5.3191027  5.3060225
 5.32424273 5.26418858 5.29806265 5.29636797 5.27005908 5.31612757
 5.28022515 5.30298576 5.30352445 5.28723704 5.32733469 5.2936338
 5.30367114 5.32564745 5.29670709 5.28465861 3.24165939 5.30176473
 5.31308691 5.2517885  5.17398308 4.66741714 5.27203252 5.31780822
 5.27815096 5.2725795  5.27864316 5.30186782 5.28730287 5.28039463
 5.30315021 5.30197053 5.30401692 5.26181026 5.30664106 5.28560398
 4.38299644 5.36857352 5.30354103 5.27813539 5.26087957 5.28760679
 5.27608605 5.2575195  5.1795225  5.36232133 5.29693958 5.31630312
 5.2883697  5.3836217  3.38078268 4.51321809 5.32672134 5.28776342
 5.3091582  5.26007868 4.96002203 4.26065128 5.30193174 5.27143515
 5.28711563 5.32089015 5.32020815 5.2956834  4.96073847 4.75947623
 3.55180143 5.31558015 5.27147552 5.27643439 4.07095807 4.86559133
 3.91245099 4.29375575 4.21906207 3.91937443 3.97593883 5.16380144
 4.94268191 5.01425735 5.18805415 5.30153545 5.33222261 5.37550746
 5.26190017 5.29487083 5.32528766 5.36792812 5.37753297 5.36644901
 5.33076752 5.29553029 2.91749918 4.48144399 5.39340791 5.2799895
 5.37030599 5.3433866  5.33774302 5.26409546 5.25655547 5.24651993
 5.33830958 5.2624095  5.26458103 5.30338605 5.26542143 5.14014569
 5.26579453 5.25342147 5.38266498 5.25178073 5.27702515 5.26050386
 5.27433806 5.30593104 5.25062272 5.2836511  5.07366152 5.37114893
 5.04565267 4.30477643 5.28035019 5.27736379 5.27702246 5.29951343
 4.63346354 5.01450179 5.28615454 5.25199591 5.35867281 5.1715706
 5.29713663 4.88420053 5.27495692 5.32246553 5.29662787 5.30573254
 5.27347215 5.39829875 5.00674116 5.32414825 5.40072414 5.29746082
 5.20563164 5.12706754 5.2647773  5.28844316 4.4221647  5.12670798
 5.29267265 5.27437145 5.37917269 5.1821158  5.27279147 5.26456263
 5.39033362 5.36036609 5.29400753 5.27068414 5.28198468 5.31660668
 5.29238953 5.34303586 5.37375811 5.26667427 5.32559292 5.39007092
 5.38696385 5.37520511 5.33282535]
objective_value: 15.997077608594946
losses: tensor([30.9386, 15.9971], dtype=torch.float64, grad_fn=<StackBackward0>)
n_obj_evaluations: 40
n_grad_evaluations: 40
