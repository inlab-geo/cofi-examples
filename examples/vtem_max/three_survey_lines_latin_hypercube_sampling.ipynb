{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latin hypercube sampling of the objective function in three survey line example\n",
    "\n",
    "<!-- Please leave the cell below as it is -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://img.shields.io/badge/open%20in-Colab-b5e2fa?logo=googlecolab&style=flat-square&color=ffd670)](https://colab.research.google.com/github/inlab-geo/cofi-examples/blob/main/examples/airborne_em/airborne_em_three_lines_transmitters.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Again, please don't touch the markdown cell above. We'll generate badge \n",
    "     automatically from the above cell. -->\n",
    "\n",
    "<!-- This cell describes things related to environment setup, so please add more text \n",
    "     if something special (not listed below) is needed to run this notebook -->\n",
    "\n",
    "> If you are running this notebook locally, make sure you've followed [steps here](https://github.com/inlab-geo/cofi-examples#run-the-examples-with-cofi-locally)\n",
    "to set up the environment. (This [environment.yml](https://github.com/inlab-geo/cofi-examples/blob/main/envs/environment.yml) file\n",
    "specifies a list of packages required to run the notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------- #\n",
    "#                                                          #\n",
    "#     Uncomment below to set up environment on \"colab\"     #\n",
    "#                                                          #\n",
    "# -------------------------------------------------------- #\n",
    "\n",
    "# !pip install -U cofi\n",
    "# !pip install git+https://github.com/JuergHauser/PyP223.git\n",
    "# !pip install smt\n",
    "# !git clone https://github.com/inlab-geo/cofi-examples.git\n",
    "# %cd cofi-examples/examples/vtem_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this notebook is run locally PyP223 and smt need to be installed separately by uncommenting the following lines, \n",
    "# that is by removing the # and the white space between it and the exclamation mark.\n",
    "# !pip install git+https://github.com/JuergHauser/PyP223.git\n",
    "# !pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import smt\n",
    "import smt.sampling_methods\n",
    "import tqdm\n",
    "from vtem_max_forward_lib import (\n",
    "    problem_setup, \n",
    "    system_spec, \n",
    "    survey_setup, \n",
    "    ForwardWrapper\n",
    ")\n",
    "\n",
    "numpy.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "The time required to solve the forward problem is what frequently dominates the time required to solve an inverse problem. An approximate mathematical model also known as a surrogate model may be constructed and used instead of the full forward problem with the advantage that evaluating the approximate model typically only takes a fraction of the time required to solve the full forward problem. The surrogate modelling toolbox ([https://github.com/SMTorg/smt](https://github.com/SMTorg/smt)) is a Python library that provides a range of surrogate modelling methods. \n",
    "\n",
    "https://github.com/SMTorg/smt/blob/master/tutorial/SMT_Tutorial.ipynb\n",
    "\n",
    "Here we use the surrogate modelling toolbox to creata surrogate model for the objective function used in the [three survey line example](http://127.0.0.1:8888/notebooks/three_survey_lines.ipynb). This notebook generates training and test/validation samples of the objective function using latin hypercube sampling. Compared to random sampling [latin hypercube sampling](https://en.wikipedia.org/wiki/Latin_hypercube_sampling) seeks to ensure that the set of random numbers is representative of the real variability. The training samples are used to create the surrogate model and the test samples are used to assess its predictive power.\n",
    "\n",
    "For large numbers of samples it can be be convenient to convert the notebook into a script and run it from the comand line, using the following command to create the script.\n",
    "\n",
    "`jupyter nbconvert --to script three_survey_lines_latin_hypercube_sampling.ipynb`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the number of training and test samples\n",
    "ntrain=100\n",
    "ntest=25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_min = 115\n",
    "tx_max = 281\n",
    "tx_interval = 15\n",
    "ty_min = 25\n",
    "ty_max = 176\n",
    "ty_interval = 75\n",
    "tx_points = numpy.arange(tx_min, tx_max, tx_interval)\n",
    "ty_points = numpy.arange(ty_min, ty_max, ty_interval)\n",
    "n_transmitters = len(tx_points) * len(ty_points)\n",
    "tx, ty = numpy.meshgrid(tx_points, ty_points)\n",
    "tx = tx.flatten()\n",
    "ty = ty.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiducial_id = numpy.arange(len(tx))\n",
    "line_id = numpy.zeros(len(tx), dtype=int)\n",
    "line_id[ty==ty_points[0]] = 0\n",
    "line_id[ty==ty_points[1]] = 1\n",
    "line_id[ty==ty_points[2]] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_setup = {\n",
    "    \"tx\": tx,                                                   # transmitter easting/x-position\n",
    "    \"ty\": ty,                                                   # transmitter northing/y-position\n",
    "    \"tz\": numpy.array([50]*n_transmitters),                     # transmitter height/z-position\n",
    "    \"tazi\": numpy.deg2rad(numpy.array([90]*n_transmitters)),    # transmitter azimuth\n",
    "    \"tincl\": numpy.deg2rad(numpy.array([6]*n_transmitters)),    # transmitter inclination\n",
    "    \"rx\": tx,                                                   # receiver easting/x-position\n",
    "    \"ry\": numpy.array([100]*n_transmitters),                    # receiver northing/y-position\n",
    "    \"rz\": numpy.array([50]*n_transmitters),                     # receiver height/z-position\n",
    "    \"trdx\": numpy.array([0]*n_transmitters),                    # transmitter receiver separation inline\n",
    "    \"trdy\": numpy.array([0]*n_transmitters),                    # transmitter receiver separation crossline\n",
    "    \"trdz\": numpy.array([0]*n_transmitters),                    # transmitter receiver separation vertical\n",
    "    \"fiducial_id\": fiducial_id,                                 # unique id for each transmitter\n",
    "    \"line_id\": line_id                  # id for each line\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_model = {\n",
    "    \"res\": numpy.array([300, 1000]), \n",
    "    \"thk\": numpy.array([25]), \n",
    "    \"peast\": numpy.array([175]), \n",
    "    \"pnorth\": numpy.array([100]), \n",
    "    \"ptop\": numpy.array([30]), \n",
    "    \"pres\": numpy.array([0.1]), \n",
    "    \"plngth1\": numpy.array([100]), \n",
    "    \"plngth2\": numpy.array([100]), \n",
    "    \"pwdth1\": numpy.array([0.1]), \n",
    "    \"pwdth2\": numpy.array([90]), \n",
    "    \"pdzm\": numpy.array([75]),\n",
    "    \"pdip\": numpy.array([60])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pdip', 'pdzm', 'peast', 'ptop', 'pwdth2']\n"
     ]
    }
   ],
   "source": [
    "forward = ForwardWrapper(true_model, problem_setup, system_spec, survey_setup,\n",
    "                         [\"pdip\",\"pdzm\", \"peast\", \"ptop\", \"pwdth2\"], data_returned=[\"vertical\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pdip', 'pdzm', 'peast', 'ptop', 'pwdth2']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the order of parameters in a model vector\n",
    "forward.params_to_invert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_param_value = numpy.array([60,65, 175, 30, 90])\n",
    "xtrue=true_param_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate synthetic data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data \n",
    "absolute_noise= 0.05\n",
    "\n",
    "# create data and ad a realisation of the noise\n",
    "data_pred_true = forward(true_param_value)\n",
    "data_obs = data_pred_true + numpy.random.randn(len(data_pred_true))*absolute_noise\n",
    "\n",
    "# define data covariance matrix\n",
    "sigma=absolute_noise\n",
    "Cdinv=numpy.identity(len(data_obs))*(1.0/(sigma*sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Latin Hypercube sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define objective function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_objective(model):\n",
    "    dpred = forward(model)\n",
    "    residual = dpred - data_obs\n",
    "    return residual.T @ Cdinv @ residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim=len(true_param_value)\n",
    "xlimits=numpy.array([[10,80],[30,150],[150,190],[25,45],[60,120]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling = smt.sampling_methods.LHS(xlimits=xlimits,random_state=42)\n",
    "xtrain=sampling(ntrain)\n",
    "ytrain=[]\n",
    "xtest=sampling(ntest)\n",
    "ytest=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:26<00:00,  2.06s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:51<00:00,  2.06s/it]\n"
     ]
    }
   ],
   "source": [
    "for x in tqdm.tqdm(xtrain):\n",
    "    ytrain.append(my_objective(x))\n",
    "for x in tqdm.tqdm(xtest):\n",
    "    ytest.append(my_objective(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=numpy.array(xtrain)\n",
    "ytrain=numpy.array(ytrain)\n",
    "\n",
    "xtest=numpy.array(xtest)\n",
    "ytest=numpy.array(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('three_survey_lines_lhs.npy', 'wb') as f:\n",
    "    numpy.save(f,ndim)\n",
    "    numpy.save(f,xlimits)\n",
    "    numpy.save(f,xtrain)\n",
    "    numpy.save(f,ytrain)\n",
    "    numpy.save(f,xtest)\n",
    "    numpy.save(f,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Watermark\n",
    "\n",
    "<!-- Feel free to add more modules in the watermark_list below, if more packages are used -->\n",
    "<!-- Otherwise please leave the below code cell unchanged -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cofi 0.2.9\n",
      "numpy 2.1.0\n",
      "scipy 1.14.1\n",
      "matplotlib 3.9.2\n",
      "smt 2.7.0\n"
     ]
    }
   ],
   "source": [
    "watermark_list = [\"cofi\", \"numpy\", \"scipy\", \"matplotlib\",\"smt\"]\n",
    "for pkg in watermark_list:\n",
    "    pkg_var = __import__(pkg)\n",
    "    print(pkg, getattr(pkg_var, \"__version__\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "82521f8c6d46dbe13b9e99c6a95164e7b000b3cca9173433679abe48ca711ce5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
